{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled20.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMUb7OKpk//EoFQSt6ReDNJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Safalgautam3636/Starting-/blob/master/Colorizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lToYhisL8Cp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Conv2D\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imsave,imshow\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import sklearn\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "from keras.layers import UpSampling2D\n",
        "import os\n",
        "import tensorboard\n",
        "import matplotlib.pyplot  as plt\n",
        "import matplotlib.image as mpimg\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAuXfsoC8HsW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "fd25cb6d-47f3-43bc-af98-5dc3cfd0429c"
      },
      "source": [
        "path = '/content/Untitled Folder'\n",
        "#Normalizing\n",
        "scaling_data= ImageDataGenerator(rescale=1. / 256)\n",
        "#Resizing the image\n",
        "train =scaling_data.flow_from_directory(path, target_size=(256, 256), batch_size=190, class_mode=None)\n",
        "\n",
        "#Convert from RGB to Lab\n",
        "#Lets make it more simplifies we put the L-channel into X\n",
        "#We put a-b channel into Y channel\n",
        "\n",
        "X =[]\n",
        "Y =[]\n",
        "for img in train[0]:\n",
        "      lab = rgb2lab(img)\n",
        "      X.append(lab[:,:,0]) \n",
        "      Y.append(lab[:,:,1:] / 128)\n",
        "      #Here we are dividing the Y list value by 128 because we have to make that in range of[1,-1] since the 128 varies upto negativity -128 of a-b channel\n",
        "\n",
        "X = np.array(X)#convert into numpy array\n",
        "\n",
        "Y = np.array(Y)#convert into numpy array making ready to train\n",
        "X = X.reshape(X.shape+(1,)) #dimensions to be the same for X and Y'''\n",
        "\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "  "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 190 images belonging to 2 classes.\n",
            "(190, 256, 256, 1)\n",
            "(190, 256, 256, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNd55wQK8MdO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        },
        "outputId": "03fee22b-afd9-4a44-b744-4fd4170e71c8"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2, input_shape=(256, 256, 1)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(128, (3,3), activation='relu', padding='same', strides=2))\n",
        "model.add(Conv2D(256, (3,3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(256, (3,3), activation='relu', padding='same', strides=2))\n",
        "model.add(Conv2D(512, (3,3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(512, (3,3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(256, (3,3), activation='relu', padding='same'))\n",
        "#Decoding \n",
        "model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(16, (3,3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))#we use hyperbolic function because the range f a,b varries from -1,to 1\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "model.compile(optimizer='adam', loss='mse' , metrics=['accuracy'])\n",
        "model.fit(X,Y,validation_split=0.1, epochs=5, batch_size=8)\n",
        "model.save('content/testfile.model')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 128, 128, 64)      640       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 128, 128, 128)     73856     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 64, 64, 128)       147584    \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 64, 64, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 32, 32, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 32, 32, 256)       1179904   \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 32, 32, 128)       295040    \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 64, 64, 64)        73792     \n",
            "_________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2 (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 128, 128, 32)      18464     \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 128, 128, 16)      4624      \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 128, 128, 2)       290       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2 (None, 256, 256, 2)       0         \n",
            "=================================================================\n",
            "Total params: 6,219,410\n",
            "Trainable params: 6,219,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 171 samples, validate on 19 samples\n",
            "Epoch 1/5\n",
            "171/171 [==============================] - 198s 1s/step - loss: 0.0986 - accuracy: 0.5341 - val_loss: 0.0427 - val_accuracy: 0.5760\n",
            "Epoch 2/5\n",
            "171/171 [==============================] - 197s 1s/step - loss: 0.0469 - accuracy: 0.5042 - val_loss: 0.0420 - val_accuracy: 0.5565\n",
            "Epoch 3/5\n",
            "171/171 [==============================] - 198s 1s/step - loss: 0.0461 - accuracy: 0.5487 - val_loss: 0.0432 - val_accuracy: 0.4389\n",
            "Epoch 4/5\n",
            "171/171 [==============================] - 198s 1s/step - loss: 0.0452 - accuracy: 0.5052 - val_loss: 0.0422 - val_accuracy: 0.6055\n",
            "Epoch 5/5\n",
            "171/171 [==============================] - 198s 1s/step - loss: 0.0492 - accuracy: 0.5572 - val_loss: 0.0427 - val_accuracy: 0.5675\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxGtHxat8PxS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "b8fde115-7a3e-4d30-900b-11cfdbb43dfb"
      },
      "source": [
        "tf.keras.models.load_model(\n",
        "    'content/testfile.model',\n",
        "    custom_objects=None,\n",
        "    compile=True)\n",
        "im=[]\n",
        "img1=img_to_array(load_img('images/sunset.png'))\n",
        "img1 = resize(img1 ,(256,256))\n",
        "im.append(img1)\n",
        "im= np.array(img1_color, dtype=float)\n",
        "im = rgb2lab(1.0/255*img1_color)[:,:,:,0]\n",
        "im= im.reshape(img1_color.shape+(1,))\n",
        "output1 = model.predict(img1_color)\n",
        "output1 = output1*128\n",
        "result = np.zeros((256, 256, 3))\n",
        "result[:,:,0] = im[0][:,:,0]\n",
        "result[:,:,1:] = output1[0]"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-8e9221f43d08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m'content/testfile.model'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     compile=True)\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mimg1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'images/sunset.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    187\u001b[0m       \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m       \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    111\u001b[0m                   (export_dir,\n\u001b[1;32m    112\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                    constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: content/testfile.model/{saved_model.pbtxt|saved_model.pb}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLdx6GRWEiNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0yWEKz_G4Mv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 55,
      "outputs": []
    }
  ]
}